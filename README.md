# Large Language Model Analysis

## Overview

In this extensive project, we immerse ourselves in the domain of machine translation, focusing on the intricate task of translating religious texts, such as the Bhagavad Gita, between Hindi and English. Our endeavor encompasses meticulous exploration, rigorous evaluation, and insightful comparison of various machine translation models. By harnessing cutting-edge natural language processing techniques and state-of-the-art machine learning architectures, we aim to bridge linguistic barriers and foster cross-cultural communication.

## Features

### mBART-50
The mBART-50 model, short for Multilingual BART-50, represents a pinnacle in multilingual translation capabilities. Developed by Facebook AI, this model embodies versatility and precision in handling translation tasks across diverse languages. Its architecture, based on the BART (Bidirectional and Auto-Regressive Transformers) framework, enables it to capture intricate linguistic nuances and context, resulting in high-quality translations.

### No Language Left Behind (NLLB-200)
NLLB-200, part of Facebook's initiative for linguistic inclusivity, stands as a testament to breaking down language barriers worldwide. This model, built upon advanced machine translation technologies, aims to ensure that no language is left behind in the digital age. By harnessing sophisticated neural network architectures, NLLB-200 strives to deliver accurate and contextually relevant translations, empowering diverse communities to engage meaningfully across platforms.

### Google Translate
Google Translate, a household name in machine translation, offers a wide array of translation services for numerous language pairs. Leveraging a combination of rule-based algorithms and neural machine translation models, Google Translate provides seamless translations for various text inputs. While widely accessible and user-friendly, its translations may sometimes lack the depth and accuracy achieved by more specialized models.

### Additional Models
In addition to the aforementioned models, our project may explore other state-of-the-art machine translation architectures, each with its unique strengths and capabilities. These models could include Transformer-based models like m2m100 or custom-built architectures tailored to specific translation tasks.

## Dataset
- **Bhagavad Gita Dataset**: [Link](https://www.kaggle.com/datasets/a2m2a2n2/bhagwad-gita-dataset)
  - Context: The Bhagavad Gita, a revered Hindu scripture, consisting of 700 verses within the epic Mahabharata.
  - Content: 701 rows with transliterations, Hindi, and English meanings for each verse.
  
- **IIT Bombay English-Hindi Parallel Corpus**: [Link](https://www.cfilt.iitb.ac.in/iitb_parallel/)
  - Context: Parallel corpus for English-Hindi collected from various sources and corpora developed at IIT Bombay.
  - Content: Sentences, phrases, and dictionary entries for English-Hindi language pairs.

## Requirements

- Python 3.6+
- Dependencies listed in `requirements.txt`

## Contributors

- [Anubhav Gupta](https://github.com/anubhav-0910)
- [Kashish Lonpande](https://github.com/Kashishca)
- [Chintan Chawda](https://github.com/imperialrogers)
- [Rohit Chaudhari](https://github.com/Rohit-gits0)

## Acknowledgments

We extend our sincere gratitude to Dr. Animesh Chaturvedi for his invaluable guidance and support throughout the duration of this project. His expertise and encouragement have been instrumental in shaping our research endeavors and fostering our growth as aspiring researchers.
